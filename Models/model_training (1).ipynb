{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_8iGzWPcwd"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "import math\n",
        "from time import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard, CSVLogger#, LearningRateScheduler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from sklearn.datasets import make_multilabel_classification\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "# import tensorflow_hub as hub\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "from model8 import model\n",
        "import argparse\n",
        "import gc\n",
        "import random"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEUJr8WkKZ7a",
        "outputId": "977f3333-9063-40c1-c1c8-a1417a000828"
      },
      "source": [
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J032y_dFbO-P"
      },
      "source": [
        "weight_dir = '/content/drive/MyDrive/weights_C3D_sports1M_tf.h5'"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVmpgb3-bZpm"
      },
      "source": [
        "def calculate_mean_std(x, channels_first=False, verbose=0):\n",
        "    \"\"\"\n",
        "    Calculates channel-wise mean and std\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : array\n",
        "        Array representing a collection of images (frames) or\n",
        "        collection of collections of images (frames) - namely video\n",
        "    channels_first : bool, optional\n",
        "        Leave False, by default False\n",
        "    verbose : int, optional\n",
        "        1-prints out details, 0-silent mode, by default 0\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    array of shape [2, num_channels]\n",
        "        Array with per channel mean and std for all the frames\n",
        "    \"\"\"\n",
        "    ndim = x.ndim\n",
        "    assert ndim in [5,4]\n",
        "    assert channels_first == False\n",
        "    all_mean = []\n",
        "    all_std = []    \n",
        "    num_channels = x.shape[-1]\n",
        "    \n",
        "    for c in range(0, num_channels):\n",
        "        if ndim ==5: # videos\n",
        "            mean = x[:,:,:,:,c].mean()\n",
        "            std = x[:,:,:,:,c].std()\n",
        "        elif ndim ==4: # images rgb or grayscale\n",
        "            mean = x[:,:,:,c].mean()\n",
        "            std = x[:,:,:,c].std()\n",
        "        if verbose:\n",
        "            print(\"Channel %s mean before: %s\" % (c, mean))   \n",
        "            print(\"Channel %s std before: %s\" % (c, std))\n",
        "            \n",
        "        all_mean.append(mean)\n",
        "        all_std.append(std)\n",
        "    \n",
        "    return np.stack((all_mean, all_std))\n",
        "\n",
        "\n",
        "def preprocess_input(x, mean_std, divide_std=False, channels_first=False, verbose=0):\n",
        "    \"\"\"\n",
        "    Channel-wise substraction of mean from the input and optional division by std\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : array\n",
        "        Input array of images (frames) or videos\n",
        "    mean_std : array\n",
        "        Array of shape [2, num_channels] with per-channel mean and std\n",
        "    divide_std : bool, optional\n",
        "        Add division by std or not, by default False\n",
        "    channels_first : bool, optional\n",
        "        Leave False, otherwise not implemented, by default False\n",
        "    verbose : int, optional\n",
        "        1-prints out details, 0-silent mode, by default 0\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        Returns input array after applying preprocessing steps\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, dtype=np.float32)    \n",
        "    ndim = x.ndim\n",
        "    assert ndim in [5,4]\n",
        "    assert channels_first == False\n",
        "    num_channels = x.shape[-1]\n",
        "    \n",
        "    for c in range(0, num_channels):  \n",
        "        if ndim ==5: # videos\n",
        "            x[:,:,:,:,c] -= mean_std[0][c]\n",
        "            if divide_std:\n",
        "                x[:,:,:,:,c] /= mean_std[1][c]\n",
        "            if verbose:\n",
        "                print(\"Channel %s mean after preprocessing: %s\" % (c, x[:,:,:,:,c].mean()))    \n",
        "                print(\"Channel %s std after preprocessing: %s\" % (c, x[:,:,:,:,c].std()))\n",
        "        elif ndim ==4: # images rgb or grayscale\n",
        "            x[:,:,:,c] -= mean_std[0][c]\n",
        "            if divide_std:\n",
        "                x[:,:,:,c] /= mean_std[1][c]   \n",
        "            if verbose:        \n",
        "                print(\"Channel %s mean after preprocessing: %s\" % (c, x[:,:,:,c].mean()))    \n",
        "                print(\"Channel %s std after preprocessing: %s\" % (c, x[:,:,:,c].std()))            \n",
        "    return x\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYxv_2-dbkuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9956f915-3b37-4065-ffa8-b236a359b2f1"
      },
      "source": [
        "files = glob.glob('/content/drive/MyDrive/training_arr/*.avi')\n",
        "files_val = glob.glob('/content/drive/MyDrive/validation_arr/*.avi')\n",
        "print(str(files[5]))\n",
        "print(str(files_val[5]))\n",
        "\n",
        "training_labels = []\n",
        "training_files = []\n",
        "val_labels = []\n",
        "val_files = []\n",
        "\n",
        "unseen = ['recieve']"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/training_arr/teacher9763_clipped.avi\n",
            "/content/drive/MyDrive/validation_arr/argue3147_clipped.avi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYDnApolbn6n"
      },
      "source": [
        "for file in files:\n",
        "    label = re.findall('[A-Za-z]+[0-9]',str(file))[0][:-1]\n",
        "    training_labels.append(label)\n",
        "    training_files.append(str(file))\n",
        "\n",
        "for file in files_val:\n",
        "    label = re.findall('[A-Za-z]+[0-9]',str(file))[0][:-1]\n",
        "    val_labels.append(label)\n",
        "    val_files.append(str(file))\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAwSdcuYbp3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928faabc-ec08-46e0-c62e-462bdcb0e9d1"
      },
      "source": [
        "training_data = pd.DataFrame({'filename':training_files,'training_labels':training_labels})\n",
        "print(training_data)\n",
        "val_data = pd.DataFrame({'filename':val_files,'val_labels':val_labels})\n",
        "val_data = val_data[val_data['val_labels']!= 'receive']\n",
        "print(val_data)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "training_data['encoded_labels'] = label_encoder.fit_transform(training_data['training_labels'])\n",
        "val_data['encoded_labels'] = label_encoder.transform(val_data['val_labels'])\n",
        "print(training_data)\n",
        "print(val_data)\n",
        "training_data.to_csv('training_words.csv')\n",
        "val_data.to_csv('val_words.csv')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               filename training_labels\n",
            "0     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "1     /content/drive/MyDrive/training_arr/teacher976...         teacher\n",
            "2     /content/drive/MyDrive/training_arr/teacher933...         teacher\n",
            "3     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "4     /content/drive/MyDrive/training_arr/television...      television\n",
            "...                                                 ...             ...\n",
            "5328  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5329  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5330  /content/drive/MyDrive/training_arr/beautiful8...       beautiful\n",
            "5331  /content/drive/MyDrive/training_arr/beautiful7...       beautiful\n",
            "5332  /content/drive/MyDrive/training_arr/beautiful7...       beautiful\n",
            "\n",
            "[5333 rows x 2 columns]\n",
            "                                               filename val_labels\n",
            "0     /content/drive/MyDrive/validation_arr/about107...      about\n",
            "1     /content/drive/MyDrive/validation_arr/arrive19...     arrive\n",
            "2     /content/drive/MyDrive/validation_arr/always31...     always\n",
            "3     /content/drive/MyDrive/validation_arr/and2361_...        and\n",
            "4     /content/drive/MyDrive/validation_arr/always31...     always\n",
            "...                                                 ...        ...\n",
            "1189  /content/drive/MyDrive/validation_arr/wrong207...      wrong\n",
            "1190  /content/drive/MyDrive/validation_arr/write753...      write\n",
            "1191  /content/drive/MyDrive/validation_arr/yesterda...  yesterday\n",
            "1192  /content/drive/MyDrive/validation_arr/yesterda...  yesterday\n",
            "1193  /content/drive/MyDrive/validation_arr/yes2068_...        yes\n",
            "\n",
            "[1193 rows x 2 columns]\n",
            "                                               filename  ... encoded_labels\n",
            "0     /content/drive/MyDrive/training_arr/teacher974...  ...            248\n",
            "1     /content/drive/MyDrive/training_arr/teacher976...  ...            248\n",
            "2     /content/drive/MyDrive/training_arr/teacher933...  ...            248\n",
            "3     /content/drive/MyDrive/training_arr/teacher974...  ...            248\n",
            "4     /content/drive/MyDrive/training_arr/television...  ...            249\n",
            "...                                                 ...  ...            ...\n",
            "5328  /content/drive/MyDrive/training_arr/beautiful2...  ...             24\n",
            "5329  /content/drive/MyDrive/training_arr/beautiful2...  ...             24\n",
            "5330  /content/drive/MyDrive/training_arr/beautiful8...  ...             24\n",
            "5331  /content/drive/MyDrive/training_arr/beautiful7...  ...             24\n",
            "5332  /content/drive/MyDrive/training_arr/beautiful7...  ...             24\n",
            "\n",
            "[5333 rows x 3 columns]\n",
            "                                               filename  ... encoded_labels\n",
            "0     /content/drive/MyDrive/validation_arr/about107...  ...              0\n",
            "1     /content/drive/MyDrive/validation_arr/arrive19...  ...             16\n",
            "2     /content/drive/MyDrive/validation_arr/always31...  ...              8\n",
            "3     /content/drive/MyDrive/validation_arr/and2361_...  ...              9\n",
            "4     /content/drive/MyDrive/validation_arr/always31...  ...              8\n",
            "...                                                 ...  ...            ...\n",
            "1189  /content/drive/MyDrive/validation_arr/wrong207...  ...            291\n",
            "1190  /content/drive/MyDrive/validation_arr/write753...  ...            290\n",
            "1191  /content/drive/MyDrive/validation_arr/yesterda...  ...            293\n",
            "1192  /content/drive/MyDrive/validation_arr/yesterda...  ...            293\n",
            "1193  /content/drive/MyDrive/validation_arr/yes2068_...  ...            292\n",
            "\n",
            "[1193 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMp-Q5vZbrqI"
      },
      "source": [
        "videos_data = []\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBYbg4OSbuYA"
      },
      "source": [
        "# i=1\n",
        "\n",
        "# for file in training_data['filename']:\n",
        "    \n",
        "    \n",
        "#     resize=(112, 112)\n",
        "#     if i%100 == 0:\n",
        "#       print(i)\n",
        "#       print(str(file))\n",
        "\n",
        "#     cap = cv2.VideoCapture(str(file))\n",
        "#     ret = True\n",
        "#     frames=[]\n",
        "\n",
        "#     while ret == True:\n",
        "#         ret,frame = cap.read()\n",
        "#         if ret == True:\n",
        "#             frame = cv2.resize(frame,resize)\n",
        "#             frames.append(frame)\n",
        "        \n",
        "#     video = np.stack(frames,axis=0)\n",
        "#     frames,length,width,channels = video.shape\n",
        "\n",
        "\n",
        "#     video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "    \n",
        "#     mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "#     video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "#     videos_data.append(video)\n",
        "#     cap.release()\n",
        "#     i += 1\n",
        "    \n",
        "\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QePi25H-roVj"
      },
      "source": [
        "def gen_video_prep(file_loc, size):\n",
        "\n",
        "    resize = size\n",
        "\n",
        "    cap = cv2.VideoCapture(str(file_loc))\n",
        "    ret = True\n",
        "      \n",
        "    frames=[]\n",
        "\n",
        "    while ret == True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.resize(frame,resize)\n",
        "            num = np.random.randint(0,100)\n",
        "            if num < 20:\n",
        "                frame = np.flip(frame,axis=1)\n",
        "            frames.append(frame)\n",
        "          \n",
        "    video = np.stack(frames,axis=0)\n",
        "    frames, channels = video.shape[0], video.shape[3]\n",
        "\n",
        "    frame_total = 16\n",
        "    if frames >= frame_total:\n",
        "        frame_list = list(range(0,frames))\n",
        "        random.shuffle(frame_list)\n",
        "        frame_list = frame_list[:16]\n",
        "        frame_list.sort(reverse = False)\n",
        "    else:\n",
        "        frame_list = list(np.linspace(0,frames-1,16,dtype=int))\n",
        "\n",
        "    #video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "    video = video[frame_list]\n",
        "\n",
        "    mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "\n",
        "    video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "\n",
        "    cap.release()\n",
        "      \n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "  \n",
        "    return video"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCuEAyTYkP8v"
      },
      "source": [
        "def val_preprocess(files, size):\n",
        "    \n",
        "    vids = []\n",
        "\n",
        "    i = 1\n",
        "    for file in files:\n",
        "    \n",
        "        resize = size\n",
        "\n",
        "        if i%100 == 0:\n",
        "            print(i)\n",
        "            print(str(file))\n",
        "\n",
        "        cap = cv2.VideoCapture(str(file))\n",
        "        ret = True\n",
        "        \n",
        "        frames=[]\n",
        "\n",
        "        while ret == True:\n",
        "            ret, frame = cap.read()\n",
        "            if ret == True:\n",
        "                frame = cv2.resize(frame,resize)\n",
        "                frames.append(frame)\n",
        "            \n",
        "        video = np.stack(frames,axis=0)\n",
        "        frames, channels = video.shape[0], video.shape[3]\n",
        "\n",
        "        frame_total = 16\n",
        "        if frames >= frame_total:\n",
        "            frame_list = list(range(0,frames))\n",
        "            random.shuffle(frame_list)\n",
        "            frame_list = frame_list[:16]\n",
        "            frame_list.sort(reverse = False)\n",
        "        else:\n",
        "            frame_list = list(np.linspace(0,frames-1,16,dtype=int))\n",
        "\n",
        "        #video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "        video = video[frame_list]\n",
        "\n",
        "        mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "\n",
        "        video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "        vids.append(video)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        cap.release()\n",
        "        \n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "    \n",
        "    return vids"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXK0OmNpFQNV"
      },
      "source": [
        "test_vid = gen_video_prep(training_data['filename'].iloc[0], (112, 112))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdmjcVqZJl63",
        "outputId": "f7ebdcb7-01bf-4d3d-ddac-f715b6fc1b65"
      },
      "source": [
        "test_vid.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 112, 112, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYD7qr1uFP04"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n898wO2mSPei"
      },
      "source": [
        "# for step in range(num_steps):\n",
        "#     # Pick an offset within the training data, which has been randomized.\n",
        "#     # Note: we could use better randomization across epochs.\n",
        "#     offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "\n",
        "#     # Generate a minibatch.\n",
        "#     batch_data = train_dataset[offset:(offset + batch_size), :]\n",
        "#     batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "\n",
        "#     # Prepare a dictionary telling the session where to feed the minibatch.\n",
        "#     # The key of the dictionary is the placeholder node of the graph to be fed,\n",
        "#     # and the value is the numpy array to feed to it.\n",
        "#     feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "\n",
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, video_filenames, labels, batch_size) :\n",
        "      self.video_filenames = video_filenames\n",
        "      self.labels = labels\n",
        "      self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "      return (np.ceil(len(self.video_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "      batch_x = self.video_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "      batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "      return np.array([\n",
        "              gen_video_prep(file_name, (112, 112)) for file_name in batch_x]), np.array(batch_y)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOlkw1XsbyqV"
      },
      "source": [
        "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "#   conv_model = model(weight_dir, trainable = True, freeze_layer = 0)\n",
        "#   conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "#   conv_model.summary()\n",
        "#   conv_model.compile(optimizer='adam',\n",
        "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#                 metrics=['sparse_categorical_accuracy'])\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YBpJ_hxb09l"
      },
      "source": [
        "# conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "# conv_model.summary()\n",
        "\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7z7-13KcEvd"
      },
      "source": [
        ""
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waaGE0THAuxT",
        "outputId": "01d82071-2b72-4acd-9729-753b65461611"
      },
      "source": [
        "conv_model = model(weight_dir, trainable = True, freeze_layer = 0)\n",
        "conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "conv_model.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
            "_________________________________________________________________\n",
            "Pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
            "_________________________________________________________________\n",
            "Pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
            "_________________________________________________________________\n",
            "Conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
            "_________________________________________________________________\n",
            "Conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
            "_________________________________________________________________\n",
            "Pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
            "_________________________________________________________________\n",
            "Conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
            "_________________________________________________________________\n",
            "Conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
            "_________________________________________________________________\n",
            "Pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
            "_________________________________________________________________\n",
            "Conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "Conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "zero_padding3d (ZeroPadding3 (None, 2, 9, 9, 512)      0         \n",
            "_________________________________________________________________\n",
            "Pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "fc7 (Dense)                  (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc8 (Dense)                  (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "fc9 (Dense)                  (None, 298)               305450    \n",
            "=================================================================\n",
            "Total params: 65,715,242\n",
            "Trainable params: 38,059,306\n",
            "Non-trainable params: 27,655,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1vCbpI5b4ha"
      },
      "source": [
        "y = np.asarray(training_data['encoded_labels'].values)\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNfft-WYb6hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b79e4ab-6762-4cee-920b-714d3af29fe1"
      },
      "source": [
        "print(y.shape)\n",
        "y = to_categorical(y)\n",
        "print(y.shape)\n",
        "y_val = to_categorical(np.asarray(val_data['encoded_labels'].values))\n",
        "print(y_val.shape)\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5333,)\n",
            "(5333, 298)\n",
            "(1193, 298)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULaNyGTtVLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6651b1-0cc1-408a-89d6-6086dcc95ca5"
      },
      "source": [
        "gen = My_Custom_Generator(training_data['filename'].tolist(), y, 32)\n",
        "val_imgs = val_preprocess(val_data['filename'].tolist(), (112,112))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "/content/drive/MyDrive/validation_arr/arrive246_clipped.avi\n",
            "200\n",
            "/content/drive/MyDrive/validation_arr/buy3391_clipped.avi\n",
            "300\n",
            "/content/drive/MyDrive/validation_arr/deaf356_clipped.avi\n",
            "400\n",
            "/content/drive/MyDrive/validation_arr/from179_clipped.avi\n",
            "500\n",
            "/content/drive/MyDrive/validation_arr/important1774_clipped.avi\n",
            "600\n",
            "/content/drive/MyDrive/validation_arr/monkey4123_clipped.avi\n",
            "700\n",
            "/content/drive/MyDrive/validation_arr/orange1110_clipped.avi\n",
            "800\n",
            "/content/drive/MyDrive/validation_arr/room1444_clipped.avi\n",
            "900\n",
            "/content/drive/MyDrive/validation_arr/sometimes2442_clipped.avi\n",
            "1000\n",
            "/content/drive/MyDrive/validation_arr/summer1858_clipped.avi\n",
            "1100\n",
            "/content/drive/MyDrive/validation_arr/umbrella313_clipped.avi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_ewMsjv8M3"
      },
      "source": [
        "# tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISE1qpveTukS"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/model'\n",
        "log_path = '/content/drive/MyDrive/model_log' \n",
        "model_name = 'weights.best.{epoch:03d}-{accuracy:.4f}.hdf5'\n",
        "tb_path = '/content/drive/MyDrive/tb_logs'"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtWgdqYUeh1P"
      },
      "source": [
        "# def scheduler(epoch, lr):\n",
        "\n",
        "#     if epoch < 50:\n",
        "#         return lr\n",
        "#     elif epoch == 50:\n",
        "#         return lr*0.2\n",
        "#     elif epoch == 75:\n",
        "#         return lr*0.5\n",
        "#     elif epoch == 100:\n",
        "#         return lr*0.2\n",
        "#     elif epoch == 125:\n",
        "#         return lr*0.5\n",
        "#     elif epoch == 150:\n",
        "#         return lr*0.2"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B--qrQ6HRvXC"
      },
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath = os.path.join(model_path, model_name),\n",
        "        monitor = 'val_accuracy', \n",
        "        save_best_only = True, \n",
        "        mode = 'max'\n",
        "        ),\n",
        "\n",
        "    CSVLogger(\n",
        "        filename=os.path.join(log_path, 'log.csv'), \n",
        "        separator = ',', \n",
        "        append = True\n",
        "        ),\n",
        "\n",
        "    EarlyStopping(\n",
        "        monitor = 'val_loss',\n",
        "        patience = 10\n",
        "        ),\n",
        "\n",
        "    TensorBoard(\n",
        "        log_dir = tb_path,\n",
        "        histogram_freq = 10,\n",
        "        write_graph = True,\n",
        "        write_images = True,\n",
        "        write_steps_per_second = False,\n",
        "        update_freq = 'epoch',\n",
        "        profile_batch = 0,\n",
        "        embeddings_freq = 0,\n",
        "        embeddings_metadata = None\n",
        "        )#,\n",
        "\n",
        "    # LearningRateScheduler(\n",
        "    #     schedule = scheduler\n",
        "    #     ),\n",
        "    ]\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErI0_Jjio0Wu"
      },
      "source": [
        "#K.set_value(conv_model.optimizer.lr, 5e-4) # 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irqhP0DycIVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1b3ae8-3924-41b3-b179-277ded5a3294"
      },
      "source": [
        "start = time()\n",
        "conv_model.fit(gen,epochs=400,batch_size=32,callbacks=callbacks,validation_data=(val_imgs,y_val))\n",
        "print(time()-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " 11/167 [>.............................] - ETA: 31:00 - loss: 23.0287 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QidWiBYT24Gy"
      },
      "source": [
        "#new_model = load_model('/content/drive/MyDrive/model/weights.best.011-0.5702.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjCm3jEv3XA8"
      },
      "source": [
        "#new_model.fit(gen,epochs=400,batch_size=32,callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRdS6Ii5_TBU"
      },
      "source": [
        "#new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xafMXwyZ_cn4"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# retrieve weights from the 3rd Conv3D layer\n",
        "filters, biases = new_model.layers[0].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "# n_filters = outgoing channels\n",
        "outgoing_channels = 2\n",
        "n_filters, ix = outgoing_channels, 1\n",
        "for i in range(n_filters):\n",
        "    # get the filter\n",
        "    f = filters[:, :, :, :, i]\n",
        "    # plot each channel separately\n",
        "    # Range of incoming channels\n",
        "    incoming_channels = 3\n",
        "    for j in range(incoming_channels):\n",
        "        # Range of Depth of the kernel .i.e. 3\n",
        "        Depth = 3\n",
        "        for k in range(Depth):\n",
        "            #pyplot.figure(figsize=(20,9))\n",
        "            # specify subplot and turn of axis\n",
        "            ax = pyplot.subplot((outgoing_channels*3), incoming_channels, ix)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            # plot filter channel in grayscale\n",
        "            pyplot.imshow(f[:, :, k,j], cmap='gray')\n",
        "            ix += 1\n",
        "# show the figure\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm7DMGhPEje2"
      },
      "source": [
        "\n",
        "#print(new_model.layers)\n",
        "successive_outputs = [layer.output for layer in new_model.layers[:2]]\n",
        "print(new_model.input)\n",
        "visualization_model = tf.keras.models.Model(new_model.input, successive_outputs )\n",
        "x = test_vid.reshape(1,16,112,112,3)\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "layer_names = [layer.name for layer in new_model.layers]\n",
        "\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "\n",
        "    if len(feature_map.shape) == 5:\n",
        "        n_features = feature_map.shape[-1] \n",
        "        size=feature_map.shape[2]\n",
        "        display_grid = np.zeros((size, size * n_features))\n",
        "        for frame in range(1):\n",
        "            for i in range(n_features):#n_features\n",
        "              x  = feature_map[0, frame, :, :, i]\n",
        "              x -= x.mean()\n",
        "              x /= x.std ()\n",
        "              x *=  64\n",
        "              x += 128\n",
        "              x  = np.clip(x, 0, 255).astype('uint8')\n",
        "              # Tile each filter into a horizontal grid\n",
        "              display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "            scale = 20. / n_features\n",
        "            plt.figure(figsize=(scale * n_features, scale))#n_features\n",
        "            plt.title (layer_name)\n",
        "            plt.grid(False)\n",
        "            plt.imshow(display_grid, aspect='auto', cmap='magma')\n",
        "            plt.savefig(f'/content/drive/MyDrive/feature_maps/maps{frame}.png',dpi=1500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS9ni7PVGDT5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}