{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FLOW frame preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ieSLligoaG"
      },
      "source": [
        "Code to preprocess videos into their flow_x and flow_y images and return normal frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3VRwghL-J1Q",
        "outputId": "b44e6ec5-9255-48b7-a6e7-470e38412d2c"
      },
      "source": [
        "import os,sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "from PIL import Image\n",
        "import multiprocessing as mp\n",
        "import threading\n",
        "\n",
        "data_root = '/content/drive/MyDrive/flow_test2'\n",
        "bound = 15\n",
        "print(f'Number of processors: {mp.cpu_count()}')\n",
        "\n",
        "def ToImg(raw_flow, bound):\n",
        "    '''\n",
        "    rescales image pixels to the range 0-255 to by boundry scaling.\n",
        "    '''\n",
        "    flow = raw_flow\n",
        "    flow[flow>bound] = bound\n",
        "    flow[flow<-bound] = -bound\n",
        "    flow -= -bound\n",
        "    flow *= (255/float(2*bound))\n",
        "    return flow\n",
        "\n",
        "def save_flows(flows,image,img_save_loc,save_dir,num,bound):\n",
        "    '''\n",
        "    Saves x and y flows as well as default frame images to data_dir.\n",
        "    :return: return 0\n",
        "    '''\n",
        "    #rescale to 0~255 with the bound setting\n",
        "    flow_x = ToImg(flows[...,0],bound)\n",
        "    flow_y = ToImg(flows[...,1],bound)\n",
        "    if not os.path.exists(os.path.join(img_save_loc, save_dir)):\n",
        "        os.makedirs(os.path.join(img_save_loc, save_dir))\n",
        "\n",
        "    #save images\n",
        "    save_img = os.path.join(img_save_loc,save_dir, f'img_{num:05d}.jpg')\n",
        "    matplotlib.image.imsave(save_img, image)\n",
        "\n",
        "    #save flows\n",
        "    save_x = os.path.join(img_save_loc, save_dir, f'flow_x_{num:05d}.jpg')\n",
        "    save_y = os.path.join(img_save_loc, save_dir, f'flow_y_{num:05d}.jpg')\n",
        "    flow_x_img = Image.fromarray(flow_x)\n",
        "    flow_y_img = Image.fromarray(flow_y)\n",
        "    matplotlib.image.imsave(save_x, flow_x_img)\n",
        "    matplotlib.image.imsave(save_y, flow_y_img)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def val_optical_prep(file_loc, label, size):\n",
        "    '''\n",
        "    takes a video file location, video label, and desired frame size.\n",
        "\n",
        "    file_loc (str): location of video to preprocess\n",
        "\n",
        "    label (str): dtring of classification label\n",
        "\n",
        "    size (tuple): tuple of with and height dims of image resize\n",
        "\n",
        "    returns: flow_x/y and normal images to predefined data_root folder\n",
        "    '''\n",
        "\n",
        "    dir_name = file_loc.split('/')[5].split('_')[0]\n",
        "    img_save_loc = os.path.join(data_root, label)\n",
        "    if not os.path.exists(os.path.join(data_root, label)):\n",
        "        os.makedirs(os.path.join(data_root,label))\n",
        "    \n",
        "    resize = size\n",
        "\n",
        "    cap = cv2.VideoCapture(str(file_loc))\n",
        "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_num = 0\n",
        "    ret = True\n",
        "      \n",
        "    frames=[]\n",
        "\n",
        "    image,prev_image,gray,prev_gray=None,None,None,None\n",
        "    num0=0\n",
        "\n",
        "    #get all video frames\n",
        "    while ret == True:\n",
        "\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.resize(frame,resize)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = frame/255.0\n",
        "            frame = np.array(frame, dtype=np.float32)\n",
        "            frames.append(frame)\n",
        "\n",
        "    for frame in frames:\n",
        "\n",
        "        #for first frame where there is no previous frame\n",
        "        if frame_num==0:\n",
        "            image=np.zeros_like(frame)\n",
        "            gray=np.zeros_like(frame)\n",
        "            prev_gray=np.zeros_like(frame)                \n",
        "            prev_image = frame\n",
        "            prev_gray = cv2.cvtColor(prev_image,cv2.COLOR_RGB2GRAY)\n",
        "            frame_num += 1\n",
        "            continue\n",
        "\n",
        "        image = frame1\n",
        "        gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        frame_0 = prev_gray\n",
        "        frame_1 = gray\n",
        "\n",
        "        # the flow algorithm outlined in https://github.com/deepmind/kinetics-i3d\n",
        "        dtvl1=cv2.optflow.createOptFlow_DualTVL1()\n",
        "        flowDTVL1=dtvl1.calc(frame_0, frame_1, None)\n",
        "\n",
        "        #saves both flow image frames and standard frames\n",
        "        save_flows(\n",
        "            flowDTVL1, \n",
        "            image, \n",
        "            img_save_loc, \n",
        "            dir_name, \n",
        "            frame_num, \n",
        "            bound\n",
        "        )\n",
        "\n",
        "        prev_gray = gray\n",
        "        prev_image = image\n",
        "        frame_num += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    # print that video is completed\n",
        "    return print('DONE!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of processors:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1v3VoCjHLsj"
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiLIbZvVTA7-"
      },
      "source": [
        "files = glob.glob('/content/drive/MyDrive/training_arr/*.avi') \n",
        "files_val = glob.glob('/content/drive/MyDrive/validation_arr/*.avi')\n",
        "\n",
        "training_labels = []\n",
        "training_files = []\n",
        "val_labels = []\n",
        "val_files = []\n",
        "\n",
        "unseen = ['recieve']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LyFlJ9TWfcJ"
      },
      "source": [
        "for file in files:\n",
        "    label = re.findall('[A-Za-z]+[0-9]',str(file))[0][:-1]\n",
        "    training_labels.append(label)\n",
        "    training_files.append(str(file))\n",
        "    \n",
        "for file in files_val:\n",
        "    label = re.findall('[A-Za-z]+[0-9]',str(file))[0][:-1]\n",
        "    val_labels.append(label)\n",
        "    val_files.append(str(file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eun_XfAWgRN"
      },
      "source": [
        "training_data = pd.DataFrame({'filename':training_files,'training_labels':training_labels})\n",
        "val_data = pd.DataFrame({'filename':val_files,'val_labels':val_labels})\n",
        "#removing words that dont appear in training set\n",
        "val_data = val_data[val_data['val_labels'] != 'receive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0BaGQ3U3P_I"
      },
      "source": [
        "def quick_make(category, folder, size, start, end):\n",
        "    '''\n",
        "    set up preprocessing function for multithreading\n",
        "    '''\n",
        "    for i in range(start,end):\n",
        "        val_optical_prep(category.iloc[i], folder.iloc[i], (224,224))\n",
        "        print(i)\n",
        "\n",
        "def split_processing(category, folder, size, num_splits=mp.cpu_count()):\n",
        "    '''\n",
        "    function to multithread flow preprocessing\n",
        "\n",
        "    category (list): list of strings pointing to file locations\n",
        "    folder (list): list of strings of corresponding labels\n",
        "    size (tuple): tuple of image resize params (width, height)\n",
        "    num_splits (int): processors to multithread with\n",
        "    '''\n",
        "    split_size = len(category) // num_splits\n",
        "    threads = []\n",
        "    for i in range(num_splits):\n",
        "        # determine the indices of the list this thread will handle\n",
        "        start = i * split_size\n",
        "        # special case on the last chunk to account for uneven splits\n",
        "        end = None if i+1 == num_splits else (i+1) * split_size\n",
        "        # create the thread\n",
        "        threads.append(\n",
        "            threading.Thread(target=quick_make, args=(category, folder, size, start, end)))\n",
        "        threads[-1].start() # start the thread we just created\n",
        "\n",
        "    # wait for all threads to finish\n",
        "    for t in threads:\n",
        "        t.join()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDaE1bFWmLf",
        "outputId": "3eb4bfd9-d964-419f-84d8-bb26ce06a2f4"
      },
      "source": [
        "split_processing(training_data.filename, training_data.training_labels, (224,224), num_splits=mp.cpu_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-15:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-8-154a02908673>\", line 2, in quick_make\n",
            "    for i in range(start,end):\n",
            "TypeError: 'NoneType' object cannot be interpreted as an integer\n",
            "\n",
            "Exception in thread Thread-14:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-8-154a02908673>\", line 3, in quick_make\n",
            "    val_optical_prep(category.iloc[i], folder.iloc[i], (224,224))\n",
            "  File \"<ipython-input-1-2a723598e5c9>\", line 61, in val_optical_prep\n",
            "    os.makedirs(os.path.join(data_root,label))\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileExistsError: [Errno 17] File exists: '/content/drive/MyDrive/flow_test2/teacher'\n",
            "\n",
            "Exception in thread Thread-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-8-154a02908673>\", line 3, in quick_make\n",
            "    val_optical_prep(category.iloc[i], folder.iloc[i], (224,224))\n",
            "  File \"<ipython-input-1-2a723598e5c9>\", line 61, in val_optical_prep\n",
            "    os.makedirs(os.path.join(data_root,label))\n",
            "  File \"/usr/lib/python3.7/os.py\", line 223, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileExistsError: [Errno 17] File exists: '/content/drive/MyDrive/flow_test2/teacher'\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE!\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}