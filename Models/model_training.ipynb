{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_8iGzWPcwd"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "import math\n",
        "from time import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard, CSVLogger#, LearningRateScheduler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from sklearn.datasets import make_multilabel_classification\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "# import tensorflow_hub as hub\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "from model8 import model\n",
        "import argparse\n",
        "import gc\n",
        "import random"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEUJr8WkKZ7a",
        "outputId": "7e8119de-746c-4a78-8097-8bcd0f12aadc"
      },
      "source": [
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J032y_dFbO-P"
      },
      "source": [
        "weight_dir = '/content/drive/MyDrive/weights_C3D_sports1M_tf.h5'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVmpgb3-bZpm"
      },
      "source": [
        "def calculate_mean_std(x, channels_first=False, verbose=0):\n",
        "    \"\"\"\n",
        "    Calculates channel-wise mean and std\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : array\n",
        "        Array representing a collection of images (frames) or\n",
        "        collection of collections of images (frames) - namely video\n",
        "    channels_first : bool, optional\n",
        "        Leave False, by default False\n",
        "    verbose : int, optional\n",
        "        1-prints out details, 0-silent mode, by default 0\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    array of shape [2, num_channels]\n",
        "        Array with per channel mean and std for all the frames\n",
        "    \"\"\"\n",
        "    ndim = x.ndim\n",
        "    assert ndim in [5,4]\n",
        "    assert channels_first == False\n",
        "    all_mean = []\n",
        "    all_std = []    \n",
        "    num_channels = x.shape[-1]\n",
        "    \n",
        "    for c in range(0, num_channels):\n",
        "        if ndim ==5: # videos\n",
        "            mean = x[:,:,:,:,c].mean()\n",
        "            std = x[:,:,:,:,c].std()\n",
        "        elif ndim ==4: # images rgb or grayscale\n",
        "            mean = x[:,:,:,c].mean()\n",
        "            std = x[:,:,:,c].std()\n",
        "        if verbose:\n",
        "            print(\"Channel %s mean before: %s\" % (c, mean))   \n",
        "            print(\"Channel %s std before: %s\" % (c, std))\n",
        "            \n",
        "        all_mean.append(mean)\n",
        "        all_std.append(std)\n",
        "    \n",
        "    return np.stack((all_mean, all_std))\n",
        "\n",
        "\n",
        "def preprocess_input(x, mean_std, divide_std=False, channels_first=False, verbose=0):\n",
        "    \"\"\"\n",
        "    Channel-wise substraction of mean from the input and optional division by std\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    x : array\n",
        "        Input array of images (frames) or videos\n",
        "    mean_std : array\n",
        "        Array of shape [2, num_channels] with per-channel mean and std\n",
        "    divide_std : bool, optional\n",
        "        Add division by std or not, by default False\n",
        "    channels_first : bool, optional\n",
        "        Leave False, otherwise not implemented, by default False\n",
        "    verbose : int, optional\n",
        "        1-prints out details, 0-silent mode, by default 0\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        Returns input array after applying preprocessing steps\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, dtype=np.float32)    \n",
        "    ndim = x.ndim\n",
        "    assert ndim in [5,4]\n",
        "    assert channels_first == False\n",
        "    num_channels = x.shape[-1]\n",
        "    \n",
        "    for c in range(0, num_channels):  \n",
        "        if ndim ==5: # videos\n",
        "            x[:,:,:,:,c] -= mean_std[0][c]\n",
        "            if divide_std:\n",
        "                x[:,:,:,:,c] /= mean_std[1][c]\n",
        "            if verbose:\n",
        "                print(\"Channel %s mean after preprocessing: %s\" % (c, x[:,:,:,:,c].mean()))    \n",
        "                print(\"Channel %s std after preprocessing: %s\" % (c, x[:,:,:,:,c].std()))\n",
        "        elif ndim ==4: # images rgb or grayscale\n",
        "            x[:,:,:,c] -= mean_std[0][c]\n",
        "            if divide_std:\n",
        "                x[:,:,:,c] /= mean_std[1][c]   \n",
        "            if verbose:        \n",
        "                print(\"Channel %s mean after preprocessing: %s\" % (c, x[:,:,:,c].mean()))    \n",
        "                print(\"Channel %s std after preprocessing: %s\" % (c, x[:,:,:,c].std()))            \n",
        "    return x\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYxv_2-dbkuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82d0739-e6c6-4e51-ec6d-48ed82323af6"
      },
      "source": [
        "files = glob.glob('/content/drive/MyDrive/training_arr/*.avi')\n",
        "print(str(files[5]))\n",
        "\n",
        "training_labels = []\n",
        "training_files = []"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/training_arr/television10367_clipped.avi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYDnApolbn6n"
      },
      "source": [
        "for file in files:\n",
        "    label = re.findall('[A-Za-z]+[0-9]',str(file))[0][:-1]\n",
        "    training_labels.append(label)\n",
        "    training_files.append(str(file))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAwSdcuYbp3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ef0184-d4c9-4809-8d26-5eed2c997c39"
      },
      "source": [
        "training_data = pd.DataFrame({'filename':training_files,'training_labels':training_labels})\n",
        "print(training_data)\n",
        "\n",
        "print(training_data)\n",
        "label_encoder = LabelEncoder().fit_transform(training_data['training_labels'])\n",
        "training_data['encoded_labels'] = label_encoder\n",
        "print(training_data)\n",
        "training_data.to_csv('training_words.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               filename training_labels\n",
            "0     /content/drive/MyDrive/training_arr/teacher778...         teacher\n",
            "1     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "2     /content/drive/MyDrive/training_arr/teacher976...         teacher\n",
            "3     /content/drive/MyDrive/training_arr/teacher933...         teacher\n",
            "4     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "...                                                 ...             ...\n",
            "5328  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5329  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5330  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5331  /content/drive/MyDrive/training_arr/beautiful8...       beautiful\n",
            "5332  /content/drive/MyDrive/training_arr/beautiful7...       beautiful\n",
            "\n",
            "[5333 rows x 2 columns]\n",
            "                                               filename training_labels\n",
            "0     /content/drive/MyDrive/training_arr/teacher778...         teacher\n",
            "1     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "2     /content/drive/MyDrive/training_arr/teacher976...         teacher\n",
            "3     /content/drive/MyDrive/training_arr/teacher933...         teacher\n",
            "4     /content/drive/MyDrive/training_arr/teacher974...         teacher\n",
            "...                                                 ...             ...\n",
            "5328  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5329  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5330  /content/drive/MyDrive/training_arr/beautiful2...       beautiful\n",
            "5331  /content/drive/MyDrive/training_arr/beautiful8...       beautiful\n",
            "5332  /content/drive/MyDrive/training_arr/beautiful7...       beautiful\n",
            "\n",
            "[5333 rows x 2 columns]\n",
            "                                               filename  ... encoded_labels\n",
            "0     /content/drive/MyDrive/training_arr/teacher778...  ...            248\n",
            "1     /content/drive/MyDrive/training_arr/teacher974...  ...            248\n",
            "2     /content/drive/MyDrive/training_arr/teacher976...  ...            248\n",
            "3     /content/drive/MyDrive/training_arr/teacher933...  ...            248\n",
            "4     /content/drive/MyDrive/training_arr/teacher974...  ...            248\n",
            "...                                                 ...  ...            ...\n",
            "5328  /content/drive/MyDrive/training_arr/beautiful2...  ...             24\n",
            "5329  /content/drive/MyDrive/training_arr/beautiful2...  ...             24\n",
            "5330  /content/drive/MyDrive/training_arr/beautiful2...  ...             24\n",
            "5331  /content/drive/MyDrive/training_arr/beautiful8...  ...             24\n",
            "5332  /content/drive/MyDrive/training_arr/beautiful7...  ...             24\n",
            "\n",
            "[5333 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMp-Q5vZbrqI"
      },
      "source": [
        "videos_data = []\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBYbg4OSbuYA"
      },
      "source": [
        "# i=1\n",
        "\n",
        "# for file in training_data['filename']:\n",
        "    \n",
        "    \n",
        "#     resize=(112, 112)\n",
        "#     if i%100 == 0:\n",
        "#       print(i)\n",
        "#       print(str(file))\n",
        "\n",
        "#     cap = cv2.VideoCapture(str(file))\n",
        "#     ret = True\n",
        "#     frames=[]\n",
        "\n",
        "#     while ret == True:\n",
        "#         ret,frame = cap.read()\n",
        "#         if ret == True:\n",
        "#             frame = cv2.resize(frame,resize)\n",
        "#             frames.append(frame)\n",
        "        \n",
        "#     video = np.stack(frames,axis=0)\n",
        "#     frames,length,width,channels = video.shape\n",
        "\n",
        "\n",
        "#     video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "    \n",
        "#     mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "#     video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "#     videos_data.append(video)\n",
        "#     cap.release()\n",
        "#     i += 1\n",
        "    \n",
        "\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QePi25H-roVj"
      },
      "source": [
        "def gen_video_prep(file_loc, size):\n",
        "\n",
        "    resize = size\n",
        "\n",
        "    cap = cv2.VideoCapture(str(file_loc))\n",
        "    ret = True\n",
        "      \n",
        "    frames=[]\n",
        "\n",
        "    while ret == True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.resize(frame,resize)\n",
        "            num = np.random.randint(0,100)\n",
        "            if num < 20:\n",
        "                frame = np.flip(frame,axis=1)\n",
        "            frames.append(frame)\n",
        "          \n",
        "    video = np.stack(frames,axis=0)\n",
        "    frames, channels = video.shape[0], video.shape[3]\n",
        "\n",
        "    frame_total = 16\n",
        "    if frames >= frame_total:\n",
        "        frame_list = list(range(0,frames))\n",
        "        random.shuffle(frame_list)\n",
        "        frame_list = frame_list[:16]\n",
        "        frame_list.sort(reverse = False)\n",
        "    else:\n",
        "        frame_list = list(np.linspace(0,frames-1,16,dtype=int))\n",
        "\n",
        "    #video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "    video = video[frame_list]\n",
        "\n",
        "    mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "\n",
        "    video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "\n",
        "    cap.release()\n",
        "      \n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "  \n",
        "    return video"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCuEAyTYkP8v"
      },
      "source": [
        "def val_preprocess(file_loc, size):\n",
        "\n",
        "    resize = size\n",
        "\n",
        "    cap = cv2.VideoCapture(str(file_loc))\n",
        "    ret = True\n",
        "      \n",
        "    frames=[]\n",
        "\n",
        "    while ret == True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.resize(frame,resize)\n",
        "            frames.append(frame)\n",
        "          \n",
        "    video = np.stack(frames,axis=0)\n",
        "    frames, channels = video.shape[0], video.shape[3]\n",
        "\n",
        "    frame_total = 16\n",
        "    if frames >= frame_total:\n",
        "        frame_list = list(range(0,frames))\n",
        "        random.shuffle(frame_list)\n",
        "        frame_list = frame_list[:16]\n",
        "        frame_list.sort(reverse = False)\n",
        "    else:\n",
        "        frame_list = list(np.linspace(0,frames-1,16,dtype=int))\n",
        "\n",
        "    #video = video[list(np.linspace(0,frames-1,16,dtype=int))]\n",
        "    video = video[frame_list]\n",
        "\n",
        "    mean_std = calculate_mean_std(video, channels_first=False, verbose=0)\n",
        "\n",
        "    video = preprocess_input(video, mean_std, divide_std=False, channels_first=False, verbose=0)\n",
        "\n",
        "    cap.release()\n",
        "      \n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "  \n",
        "    return video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n898wO2mSPei"
      },
      "source": [
        "# for step in range(num_steps):\n",
        "#     # Pick an offset within the training data, which has been randomized.\n",
        "#     # Note: we could use better randomization across epochs.\n",
        "#     offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "\n",
        "#     # Generate a minibatch.\n",
        "#     batch_data = train_dataset[offset:(offset + batch_size), :]\n",
        "#     batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "\n",
        "#     # Prepare a dictionary telling the session where to feed the minibatch.\n",
        "#     # The key of the dictionary is the placeholder node of the graph to be fed,\n",
        "#     # and the value is the numpy array to feed to it.\n",
        "#     feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "\n",
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "  def __init__(self, video_filenames, labels, batch_size) :\n",
        "      self.video_filenames = video_filenames\n",
        "      self.labels = labels\n",
        "      self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "  def __len__(self) :\n",
        "      return (np.ceil(len(self.video_filenames) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, idx) :\n",
        "      batch_x = self.video_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "      batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "      return np.array([\n",
        "              gen_video_prep(file_name, (112, 112)) for file_name in batch_x]), np.array(batch_y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOlkw1XsbyqV"
      },
      "source": [
        "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "#   conv_model = model(weight_dir, trainable = True, freeze_layer = 0)\n",
        "#   conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "#   conv_model.summary()\n",
        "#   conv_model.compile(optimizer='adam',\n",
        "#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#                 metrics=['sparse_categorical_accuracy'])\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YBpJ_hxb09l"
      },
      "source": [
        "# conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "# conv_model.summary()\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waaGE0THAuxT",
        "outputId": "e4aa929e-19a2-4542-f282-41ad82b2f9aa"
      },
      "source": [
        "conv_model = model(weight_dir, trainable = True, freeze_layer = 0)\n",
        "conv_model = conv_model.retrainable_model((3, 3, 3), (16, 112, 112, 3))\n",
        "conv_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
            "_________________________________________________________________\n",
            "Pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
            "_________________________________________________________________\n",
            "Pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
            "_________________________________________________________________\n",
            "Conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
            "_________________________________________________________________\n",
            "Conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
            "_________________________________________________________________\n",
            "Pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
            "_________________________________________________________________\n",
            "Conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
            "_________________________________________________________________\n",
            "Conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
            "_________________________________________________________________\n",
            "Pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
            "_________________________________________________________________\n",
            "Conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "Conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "zero_padding3d (ZeroPadding3 (None, 2, 9, 9, 512)      0         \n",
            "_________________________________________________________________\n",
            "Pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "fc7 (Dense)                  (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "fc8 (Dense)                  (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "fc9 (Dense)                  (None, 298)               305450    \n",
            "=================================================================\n",
            "Total params: 65,715,242\n",
            "Trainable params: 38,059,306\n",
            "Non-trainable params: 27,655,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1vCbpI5b4ha"
      },
      "source": [
        "y = np.asarray(training_data['encoded_labels'].values)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNfft-WYb6hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb98a8e0-8525-42b0-a693-562b425d7a0f"
      },
      "source": [
        "print(y.shape)\n",
        "y = to_categorical(y)\n",
        "print(y.shape)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5333,)\n",
            "(5333, 298)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ULaNyGTtVLU"
      },
      "source": [
        "gen = My_Custom_Generator(training_data['filename'].tolist(), y, 32)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_ewMsjv8M3"
      },
      "source": [
        "# tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISE1qpveTukS"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/model'\n",
        "log_path = '/content/drive/MyDrive/model_log' \n",
        "model_name = 'weights.best.{epoch:03d}-{accuracy:.4f}.hdf5'\n",
        "tb_path = '/content/drive/MyDrive/tb_logs'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtWgdqYUeh1P"
      },
      "source": [
        "# def scheduler(epoch, lr):\n",
        "\n",
        "#     if epoch < 50:\n",
        "#         return lr\n",
        "#     elif epoch == 50:\n",
        "#         return lr*0.2\n",
        "#     elif epoch == 75:\n",
        "#         return lr*0.5\n",
        "#     elif epoch == 100:\n",
        "#         return lr*0.2\n",
        "#     elif epoch == 125:\n",
        "#         return lr*0.5\n",
        "#     elif epoch == 150:\n",
        "#         return lr*0.2"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B--qrQ6HRvXC"
      },
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath = os.path.join(model_path, model_name),\n",
        "        monitor = 'accuracy', \n",
        "        save_best_only = True, \n",
        "        mode = 'max'\n",
        "        ),\n",
        "\n",
        "    CSVLogger(\n",
        "        filename=os.path.join(log_path, 'log.csv'), \n",
        "        separator = ',', \n",
        "        append = True\n",
        "        ),\n",
        "\n",
        "    EarlyStopping(\n",
        "        monitor = 'loss',\n",
        "        patience = 10\n",
        "        ),\n",
        "\n",
        "    TensorBoard(\n",
        "        log_dir = tb_path,\n",
        "        histogram_freq = 10,\n",
        "        write_graph = True,\n",
        "        write_images = True,\n",
        "        write_steps_per_second = False,\n",
        "        update_freq = 'epoch',\n",
        "        profile_batch = 0,\n",
        "        embeddings_freq = 0,\n",
        "        embeddings_metadata = None\n",
        "        )#,\n",
        "\n",
        "    # LearningRateScheduler(\n",
        "    #     schedule = scheduler\n",
        "    #     ),\n",
        "    ]\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErI0_Jjio0Wu"
      },
      "source": [
        "K.set_value(conv_model.optimizer.lr, 5e-4) # 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irqhP0DycIVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7417e311-70ba-45a6-9e71-59fb6b94c5bc"
      },
      "source": [
        "start = time()\n",
        "conv_model.fit(gen,epochs=400,batch_size=32,callbacks=callbacks)\n",
        "print(time()-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "167/167 [==============================] - 137s 818ms/step - loss: 2.2870 - accuracy: 0.4894\n",
            "Epoch 2/400\n",
            "167/167 [==============================] - 133s 797ms/step - loss: 2.2400 - accuracy: 0.4956\n",
            "Epoch 3/400\n",
            "167/167 [==============================] - 134s 801ms/step - loss: 2.1743 - accuracy: 0.5097\n",
            "Epoch 4/400\n",
            "167/167 [==============================] - 136s 812ms/step - loss: 2.1147 - accuracy: 0.5263\n",
            "Epoch 5/400\n",
            "  5/167 [..............................] - ETA: 2:11 - loss: 2.1398 - accuracy: 0.5188"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}